# model Compression
* [Domain-adaptive deep network compression](https://arxiv.org/abs/1709.01041)
# pruning
* [ThiNet:A Filter Level Pruning Method for Deep Neural Network Compression](https://arxiv.org/abs/1707.06342)
* [Channel Pruning for Accelerating Very Deep Neural Networks](http://openaccess.thecvf.com/content_ICCV_2017/papers/He_Channel_Pruning_for_ICCV_2017_paper.pdf)
# quantization
* [Performance Guaranteed Network Acceleration via High-Order Residual Quantization](http://openaccess.thecvf.com/content_ICCV_2017/papers/Li_Performance_Guaranteed_Network_ICCV_2017_paper.pdf)
# other
* [Centered Weight Normalization in Accelerating Training of Deep Neural Networks](http://openaccess.thecvf.com/content_ICCV_2017/papers/Huang_Centered_Weight_Normalization_ICCV_2017_paper.pdf)

# model compression
* [Compressing Neural Networks using the Variational Information Bottleneck](https://arxiv.org/abs/1802.10399?context=cs.CV)
* [Curriculum Learning by Transfer Learning: Theory and Experiments with Deep Networks](https://arxiv.org/abs/1802.03796)
* [Weightless: Lossy Weight Encoding For Deep Neural Network Compression](https://arxiv.org/abs/1711.04686?context=stat.ML)
* [Deep k-Means: Re-Training and Parameter Sharing with Harder Cluster Assignments for Compressing Deep Convolutions](http://cn.arxiv.org/abs/1806.09228)
* [Understanding Generalization and Optimization Performance of Deep CNNs](https://arxiv.org/abs/1805.10767v1)
* [Stronger Generalization Bounds for Deep Nets via a Compression Approach](http://proceedings.mlr.press/v80/arora18b.html)
* [Efficient end-to-end learning for quantizable representations](http://proceedings.mlr.press/v80/jeong18a.html)
* [Learning to Speed Up Structured Output Prediction](http://proceedings.mlr.press/v80/pan18b.html)
* [On the Optimization of Deep Networks: Implicit Acceleration by Overparameterization](http://proceedings.mlr.press/v80/arora18a.html)
* [Understanding Generalization and Optimization Performance of Deep CNNs](http://proceedings.mlr.press/v80/zhou18a.html)
* [Curriculum Learning by Transfer Learning: Theory and Experiments with Deep Networks](http://proceedings.mlr.press/v80/weinshall18a.html)
* [Exploring Hidden Dimensions in Accelerating Convolutional Neural Networks](http://proceedings.mlr.press/v80/jia18a.html)
